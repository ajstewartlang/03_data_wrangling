---
title: "Data Wrangling"
author: ""
date: ""
output: 
  html_document:
    theme: flatly
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview 

In this workshop we shall take our first look at some key tools in the [Tidyverse](https://www.tidyverse.org) that will allow us to wrangle and tidy our data so that it's in the format that we need in order to visualize and model it. The Tidyverse is a collection of packages that all 'play nicely' with each other. They are based on a common philosophy where data are represented in rectangular format (i.e., with rows and columns). These rectangular structures are known in the Tidyverse as `tibbles`. If you're interested, you can read more about `tibbles` in the R4DS book [here](https://r4ds.had.co.nz/tibbles.html).

Have a look at the following video where I walk you through this worksheet. Then I want you to work through the content by writing (and running) the script on your own machine.

&nbsp;&nbsp;

<center>

<iframe width="560" height="315" src="https://youtube.com/embed/IvI4VacAZPI" frameborder="0" allowfullscreen></iframe>

</center>
&nbsp;&nbsp;

# Loading the Tidyverse

Let's take our first look at data wrangling. We are going to start with a dataset that comes with the Tidyverse. The dataset is called `mpg` and comprises fuel economy data from 1999 to 2008 for 38 popular models of cars in the US.

First, we need to load the `tidyverse` library with the following:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
```

If you run this line without having first installed the Tidyverse on your computer, you will encounter an error. R packages only need to be installed once, so if you want to load one into your library for the first time, you need to install it with `install.packages(*packagename*)`.

For the `tidyverse` we need to install it with:

```{r, eval=FALSE}
install.packages(tidyverse)
```

Once you have installed the `tidyverse`, you can then load it into your llbrary with the `library()` function. You only ever need to install a package once on your machine (unless you have updated R or you want to install the most up-to-date version of a particular package). When you are writing your R scripts, you never want to have the `install.packages()` function in the body of the script as if someone else were to run your script, this would update packages on their computer (which they might not want).

## The `mpg` dataset

The `mpg` dataset is loaded as part of the Tidyverse In the help file, which you can access by typing `help(mpg)` or `?mpg` we see the following:

Description
This dataset contains a subset of the fuel economy data that the EPA makes available on http://fueleconomy.gov. It contains only models which had a new release every year between 1999 and 2008 - this was used as a proxy for the popularity of the car.

A data frame with 234 rows and 11 variables.

manufacturer - manufacturer
model - model name
displ - engine displacement, in litres
year - year of manufacture
cyl - number of cylinders
trans -type of transmission
drv -f = front-wheel drive, r = rear wheel drive, 4 = 4wd
cty - city miles per gallon
hwy - highway miles per gallon
fl - fuel type
class - "type" of car

# Using `head()` and `str()`

We can explore the `mpg` dataset that is loaded with the Tidyverse in a number of ways. If we want to look at the first 6 lines of the dataset, we can use the `head()` function.

```{r}
head(mpg)
```

We see that it is a tibble - or a rectangular data frame - made up of rows and columns. This is `tidy` format where each observation corresponds to a row. Most of the analyses we will run in R involve `tidy` data. Within the Tidyverse, the `tibble` is the standard way to represent data. You'll spend a lot of time tidying and wrangling your data to get it into this format! By doing this in R using a script that you write, you are making this key stage *reproducible*. You can run the script again on an updated or different dataset - thus likely saving you lots of time!

We can also ask for information about the structure of our dataset with `str()`. This will tell us about the columns, what type of variable each is, the number of rows etc.

```{r}
str(mpg)
```

# Use `select()` to select columns

If we want to, we could just select one of the columns using the `select()` function. Below we are just selecing the column entitled `manufacturer`.

```{r}
mpg %>%
  select(manufacturer)
```

Related to the `select()` function is `rename()`. It does exactly what you think it might; it renames a column.

We can also look at the different car manufacturers in the dataset by using the `distinct()` function. This gives us the unique manufacturer names. This function can be quite handy if you want to check a dataset for duplicates of (e.g.) participant IDs.

```{r}
mpg %>%
  distinct(manufacturer)
```

# Use `filter()` to select rows

Sometimes we might want to select only a subset of rows in our dataset. We can do that using the `filter()` function. For example, here we filter our dataset to include only cars made by 'honda'.

```{r}
mpg %>%
  filter(manufacturer == "honda")
```

Note, we use the operator `==` which means 'is equal to'. This is a logical operator - other logical operators include less than `<`, greater than `>`, less than or equal to `<=`, greater then or equal to `>=`, and is not equal to `!=`.

We can also filter using a combination of possibilities via logical OR `|` or logical AND `&`. The first code chunk below filters the dataset for cases where the manufacturer is 'honda' OR 'toyota'.

```{r}
mpg %>%
  filter(manufacturer == "honda" | manufacturer == "toyota")
```

While below we filter for cases where the manufacturer is 'honda' and the year of manufacture is '1999'.

```{r}
mpg %>% 
  filter(manufacturer == "honda" & year == "1999")
```

## Combining functions

We can combine the use of `filter()` with `select()` to filter for case where the manufacturer is 'honda', the year of manufacture is '1999' and we only want to display these two columns plus those telling us about fuel economy - `cty` and `hwy`.

```{r}
mpg %>% 
  filter(manufacturer == "honda" & year == "1999") %>%
  select(manufacturer, year, cty, hwy)
```

By combining just a few functions, you can imagine that we can build some quite complex data wrangling rules quite straightforwardly.  

# The pipe `%>%`

Note that in these examples above we used the `%>%` operator - this is called the pipe and allows us to pass information from one side of the pipe to the other. You can read it out load as 'and then'. All of the functions (such as `select()`, `filter()` etc.) in the Tidyverse are known as verbs, and they describe what they do. The pipe is one of the most commonly used operators in the Tidyverse and allows us to chain together different lines of code - with the output of each line being passed on as input into the next. In this example, the dataset `mpg` is passed along to the `distinct()` function where we ask for a list of the distinct (i.e., unique) manufacturers. This output itself is a vector. Vectors are a basic data structure and contain elements of the same type - for example, a bunch of numbers. We can add another line to our piped chain to tell us how many elements are in this vector. We could read this out loud as 'take the dataset mpg, and then work out the distinct manufacturer names, and then count them'. 

```{r}
mpg %>% 
  distinct(manufacturer) %>%
  count()
```

# Tidying up a dataset

## Tidying variable names

At the moment, the car manufacturer names are all in lower case. It would look a lot nicer if they were in title case (i.e., with capitalisation on the first letter of each word). We can use the `mutate()` function to create a new column - this time, the name of the new column is also the name of the old column that we're wanting to modify using the function `str_to_title()`. What this will do is overwrite the column `manufacturer` and replace it with the new version with the car manufacturer names in title case.

```{r}
mpg %>%
  mutate(manufacturer = str_to_title(manufacturer)) 
```

The column `model` is also lowercase. Let's make that title case too.  We can use the `mutate()` function to work over more than one column at the same time like this:

```{r}
mpg %>%
  mutate(manufacturer = str_to_title(manufacturer), model = str_to_title(model))
```

There are quite a few columns there, so how about we select just the manufacturer, model, year, transmission, and hwy columns:

```{r}
mpg %>%
  mutate(manufacturer = str_to_title(manufacturer), model = str_to_title(model)) %>%
  select(manufacturer, model, year, trans, hwy)
```

## Recoding variables 

In the real world, data frames do not always arrive on our computer in tidy format. Very often you need to engage in some data tidying before you can do anything useful with them. We're going to look at an example of how we go from messy data to tidy data.

```{r, message=FALSE}
my_messy_data <- read_csv("https://raw.githubusercontent.com/ajstewartlang/03_data_wrangling/master/data/my_data.csv")
```

We ran a reaction time experiment with 24 participants and 4 conditions - they are numbered 1-4 in our data file.

```{r}
head(my_messy_data)
```

This is a repeated measures design where we had one factor (Prime Type) with two levels (A vs. B) and a second factor (Target Type) with two levels (A vs. B). We want to recode our data frame so it better matches our experimental design. First we need to recode our 4 conditions like this:

Recode condition columns follows:
Condition 1 = Prime A, Target A
Condition 2 = Prime A, Target B
Condition 3 = Prime B, Target A
Condition 4 = Prime B, Target B

```{r}
my_messy_data %>% 
  mutate(condition = recode(condition,
                            "1" = "PrimeA_TargetA",
                            "2" = "PrimeA_TargetB", 
                            "3" = "PrimeB_TargetA", 
                            "4" = "PrimeB_TargetB")) %>%
  head()
```

We now need to separate out our Condition column into two - one for our first factor (Prime), and one for our second factor (Target). The `separate()` function does just this - when used in conjunction with a piped tibble, it needs to know which column we want to separate, what new columns to create by separating that original column, and on what basis we want to do the separation. In the example below we tell `separate()` that we want to separate the column labeled `condition` into two new columns called `Prime` and `Target` and we want to do this at any points where a `_` is present in the column to be separated.

```{r}
my_messy_data %>% 
  mutate(condition = recode(condition,
                            "1" = "PrimeA_TargetA",
                            "2" = "PrimeA_TargetB", 
                            "3" = "PrimeB_TargetA", 
                            "4" = "PrimeB_TargetB")) %>%
  separate(col = "condition", into = c("Prime", "Target"), sep = "_")
```

```{r}
my_messy_data %>% 
  mutate(condition = recode(condition,
                            "1" = "PrimeA_TargetA",
                            "2" = "PrimeA_TargetB", 
                            "3" = "PrimeB_TargetA", 
                            "4" = "PrimeB_TargetB")) %>%
  separate(col = "condition", into = c("Prime", "Target"), sep = "_") %>%
  mutate(Prime = factor(Prime), Target = factor(Target))
```

## The pivot functions

Most of the analysis we will conduct in R requires our data to be in tidy, or long, format. In such data sets, one row corresponds to one observation. In the real world, data are rarely in the right format for analysis. In R, the `pivot_wider()` and `pivot_longer()` functions are designed to reshape our data files. First, let's load a datafile that is in wide format (i.e., multiple observations per row). It is from an experiment where we had four conditions (labelled Condition1, Condition2, Condition3, and Condition4). In addition to there being a column for each of the 4 conditions, we also have a column corresponding to participant ID. Each cell in the data set corresponds to a reaction time.

# Your challenge

Have a go at recreating what I've done above by writing your first script using RStudio Desktop. 

## Improve this Workshop

If you spot any issues/errors in this workshop, you can raise an issue or create a pull request for [this repo](https://github.com/ajstewartlang/03_data_wrangling). 